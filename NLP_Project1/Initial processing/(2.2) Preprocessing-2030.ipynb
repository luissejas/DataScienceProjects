{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BOwsuGQQY9OL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aayushmarishi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urllink     im new to this, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>election time has rolled aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well, i hate to start off no such a sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was a weedy child. this wasn't so muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have developed a pain in my chest tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319967</th>\n",
       "      <td>dear susan,  i could write some really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319968</th>\n",
       "      <td>dear susan,  'i have the second yeast i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319969</th>\n",
       "      <td>dear susan,  your 'boyfriend' is fuckin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319970</th>\n",
       "      <td>dear susan:    just to clarify, i am as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319971</th>\n",
       "      <td>hey everybody...and susan,  you might a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319972 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "0                         urllink     im new to this, ...\n",
       "1                         election time has rolled aro...\n",
       "2              well, i hate to start off no such a sou...\n",
       "3              i was a weedy child. this wasn't so muc...\n",
       "4              i have developed a pain in my chest tha...\n",
       "...                                                   ...\n",
       "319967         dear susan,  i could write some really ...\n",
       "319968         dear susan,  'i have the second yeast i...\n",
       "319969         dear susan,  your 'boyfriend' is fuckin...\n",
       "319970         dear susan:    just to clarify, i am as...\n",
       "319971         hey everybody...and susan,  you might a...\n",
       "\n",
       "[319972 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Data/blog_2030.csv')\n",
    "data['text'] = data.apply(lambda row: row.text.lower(), axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_english = data.loc[data.text.str.contains(\"the\")\\\n",
    "                         ].loc[data.text.str.contains(\"and\")\\\n",
    "                              ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into sentences\n",
    "sentence_list = []\n",
    "blogs = filter_english['text'].tolist()\n",
    "for b in blogs:\n",
    "    # nltk.tokenize.sent_tokenize can split paragraphs into sentences\n",
    "    # according to common sentence-ending punctuations\n",
    "    sentences = nltk.tokenize.sent_tokenize(b)\n",
    "    \n",
    "    # Filter out sentences that include the word 'urllink'\n",
    "    sentences = ['' if 'urllink' in s else s for s in sentences]\n",
    "    \n",
    "    # Remove punctuations and filter length (both a lower and upper\n",
    "    # limit are imposed to make the data more consistent)\n",
    "    sentences = [s.strip(string.punctuation\\\n",
    "                        ).strip() if (len(s)>50 and len(s) < 150\\\n",
    "                                     ) else '' for s in sentences]\n",
    "    \n",
    "    # Filter out empty sentences\n",
    "    sentences = list(filter(None, sentences))\n",
    "    sentence_list += sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1908292 sentences in total\n"
     ]
    }
   ],
   "source": [
    "print(\"There are %d sentences in total\" % (len(sentence_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the above for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"       (it is never good to start on a digression. however)  a digression: you know those conversations that go something along these lines?  -you're in a weird mood. -no i'm not. -yes you are, what's wrong? -i'm not in a weird mood! -don't shout at me!   i hate those.   so, to the point: patriotism. in specific reference to the england football team being knocked out of [whatever tournament it is that's on at the moment] this evening. it was an exciting match, but i'm glad that england lost. note i didn't say 'we'. and why? because those eleven men playing football out there aren't doing it for me; they don't know me, i don't know them, i didn't ask them to play football for me. in no way do they represent me, and certainly not as a result of them being from the same country as me.  ergh. but i mustn't go on so. calm down.   blogger food of the day: uncle ben's express rice. genius! it comes in a packet that stands up in your microwave, it takes two minutes, you don't have to refrigerate it, and its quite tasty. especially at one in the morning when you're all toasted out.   hugs: alex and her talk of bra shopping uncle ben's express rice staplers (a bit random, i know, but they are cool, aren't they?) 'space raiders' crisps - ten pence? bargain! the manchester cow parade   slaps: indigestion from eating toast and rice too quickly   (sheesh...)  and no, i'm *not* in a mood...  n.       \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example paragraph\n",
    "display(blogs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['       (it is never good to start on a digression.',\n",
       " 'however)  a digression: you know those conversations that go something along these lines?',\n",
       " \"-you're in a weird mood.\",\n",
       " \"-no i'm not.\",\n",
       " \"-yes you are, what's wrong?\",\n",
       " \"-i'm not in a weird mood!\",\n",
       " \"-don't shout at me!\",\n",
       " 'i hate those.',\n",
       " 'so, to the point: patriotism.',\n",
       " \"in specific reference to the england football team being knocked out of [whatever tournament it is that's on at the moment] this evening.\",\n",
       " \"it was an exciting match, but i'm glad that england lost.\",\n",
       " \"note i didn't say 'we'.\",\n",
       " 'and why?',\n",
       " \"because those eleven men playing football out there aren't doing it for me; they don't know me, i don't know them, i didn't ask them to play football for me.\",\n",
       " 'in no way do they represent me, and certainly not as a result of them being from the same country as me.',\n",
       " 'ergh.',\n",
       " \"but i mustn't go on so.\",\n",
       " 'calm down.',\n",
       " \"blogger food of the day: uncle ben's express rice.\",\n",
       " 'genius!',\n",
       " \"it comes in a packet that stands up in your microwave, it takes two minutes, you don't have to refrigerate it, and its quite tasty.\",\n",
       " \"especially at one in the morning when you're all toasted out.\",\n",
       " \"hugs: alex and her talk of bra shopping uncle ben's express rice staplers (a bit random, i know, but they are cool, aren't they?)\",\n",
       " \"'space raiders' crisps - ten pence?\",\n",
       " 'bargain!',\n",
       " \"the manchester cow parade   slaps: indigestion from eating toast and rice too quickly   (sheesh...)  and no, i'm *not* in a mood...  n.\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the nltk function to split the example paragraph into sentences\n",
    "sentences = nltk.tokenize.sent_tokenize(blogs[5])\n",
    "display(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'however)  a digression: you know those conversations that go something along these lines',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " \"in specific reference to the england football team being knocked out of [whatever tournament it is that's on at the moment] this evening\",\n",
       " \"it was an exciting match, but i'm glad that england lost\",\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'in no way do they represent me, and certainly not as a result of them being from the same country as me',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " \"it comes in a packet that stands up in your microwave, it takes two minutes, you don't have to refrigerate it, and its quite tasty\",\n",
       " \"especially at one in the morning when you're all toasted out\",\n",
       " \"hugs: alex and her talk of bra shopping uncle ben's express rice staplers (a bit random, i know, but they are cool, aren't they\",\n",
       " '',\n",
       " '',\n",
       " \"the manchester cow parade   slaps: indigestion from eating toast and rice too quickly   (sheesh...)  and no, i'm *not* in a mood...  n\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strip the sentences of their punctuations and add a length filter\n",
    "sentences = [s.strip(string.punctuation\n",
    "                    ).strip() if (len(s)>50 and len(s) < 150\n",
    "                                 ) else '' for s in sentences]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['however)  a digression: you know those conversations that go something along these lines',\n",
       " \"in specific reference to the england football team being knocked out of [whatever tournament it is that's on at the moment] this evening\",\n",
       " \"it was an exciting match, but i'm glad that england lost\",\n",
       " 'in no way do they represent me, and certainly not as a result of them being from the same country as me',\n",
       " \"it comes in a packet that stands up in your microwave, it takes two minutes, you don't have to refrigerate it, and its quite tasty\",\n",
       " \"especially at one in the morning when you're all toasted out\",\n",
       " \"hugs: alex and her talk of bra shopping uncle ben's express rice staplers (a bit random, i know, but they are cool, aren't they\",\n",
       " \"the manchester cow parade   slaps: indigestion from eating toast and rice too quickly   (sheesh...)  and no, i'm *not* in a mood...  n\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete sentences that have been turned into empty strings\n",
    "sentences = list(filter(None, sentences))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>election time has rolled around again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and everyone is spitting their venom at each o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>instead of pointing your greedy little fingers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im sick of hearing what he did, how badly they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i guess it isnt like anyone is bound to believ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908287</th>\n",
       "      <td>i have been getting tired of writing my wacky ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908288</th>\n",
       "      <td>then i discovered this wonderful site called '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908289</th>\n",
       "      <td>so now i've decided to devote my sardonic song...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908290</th>\n",
       "      <td>i'll be posting bits and pieces of works in pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908291</th>\n",
       "      <td>here's two very rough parodies i've been worki...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1908292 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0\n",
       "0                    election time has rolled around again\n",
       "1        and everyone is spitting their venom at each o...\n",
       "2        instead of pointing your greedy little fingers...\n",
       "3        im sick of hearing what he did, how badly they...\n",
       "4        i guess it isnt like anyone is bound to believ...\n",
       "...                                                    ...\n",
       "1908287  i have been getting tired of writing my wacky ...\n",
       "1908288  then i discovered this wonderful site called '...\n",
       "1908289  so now i've decided to devote my sardonic song...\n",
       "1908290  i'll be posting bits and pieces of works in pr...\n",
       "1908291  here's two very rough parodies i've been worki...\n",
       "\n",
       "[1908292 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(sentence_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.sample(n = 10000).reset_index(drop=True)\n",
    "sample.to_csv('../Data/sample_2030.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample3 = df.sample(n = 5000).reset_index(drop=True)\n",
    "sample3.to_csv('../Data/sample2_2030.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Course 3 - Week 4 - Lesson 2 - Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
